{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Prompt Engineering Lab Journal","text":"<p>A personal workspace to document 9 projects testing prompt effectiveness.</p>"},{"location":"#objective","title":"\ud83e\udde0 Objective","text":"<p>To design, test, and evaluate various prompt types to understand how clarity, tone, structure, and creativity affect AI-generated outputs.</p>"},{"location":"#structure","title":"\ud83d\udcc2 Structure","text":"<p>This lab journal contains 9 projects. Each project will include:</p> <ol> <li>Prompt Type &amp; Goal \u2013 what kind of prompt is tested and why.</li> <li>Experiment Setup \u2013 tools, parameters, and method used.</li> <li>Prompt Versions \u2013 iterations of the prompt for comparison.</li> <li>Evaluation \u2013 clarity, accuracy, creativity, tone, and structure scores.</li> <li>Insights &amp; Learnings \u2013 what worked, what didn\u2019t, and takeaways.</li> </ol>"},{"location":"#tools-workspace","title":"\u2699\ufe0f Tools &amp; Workspace","text":"<ul> <li>ChatGPT / Google Gemini / Claude \u2013 for generating and testing prompts.</li> <li>Google Sheets / Excel \u2013 for logging and analyzing evaluation scores.</li> <li>Canva \u2013 for visual representations and comparison charts.</li> <li>Python &amp; MkDocs \u2013 for building and structuring this professional documentation site.</li> <li>GitHub Pages \u2013 for hosting and version control of the final portfolio.</li> </ul>"},{"location":"#evaluation-metrics","title":"\ud83d\udccf Evaluation Metrics","text":"Metric Description Clarity How clear and understandable the output is. Accuracy How closely it meets the intended goal or fact-based correctness. Tone Whether the response tone matches the context or purpose. Creativity Level of originality or uniqueness in the response. Structure How well-organized and formatted the output is."},{"location":"project-1/","title":"Project 1 \u2013 Instruction Prompts","text":""},{"location":"project-1/#prompt-type-goal","title":"Prompt Type &amp; Goal","text":"<p>Testing specificity levels in direct instruction prompts\u2014comparing how vague, basic, and detailed instructions affect the quality, accuracy, and creativity of AI-generated outputs.</p>"},{"location":"project-1/#experiment-setup","title":"Experiment Setup","text":""},{"location":"project-1/#models-and-versions","title":"Models and Versions","text":"<ul> <li>Claude Sonnet 4.5</li> <li>ChatGPT (GPT-4 or GPT-4o)</li> <li>Google Gemini (2.5 Flash)</li> <li>Perplexity AI</li> </ul>"},{"location":"project-1/#dataset-or-tasks","title":"Dataset or Tasks","text":"<p>Task: Write a product description for a fictional \"FitPulse Pro\" smartwatch</p> <p>Product details: -   Heart rate monitoring with real-time tracking -   Built-in GPS for route mapping -   7-day battery life -   Water-resistant design -   Target audience: Health-conscious professionals aged 25-40</p>"},{"location":"project-1/#hypothesis","title":"Hypothesis","text":"<p>More specific instructions will produce higher scores in Structure and Accuracy across all models, but may reduce Creativity scores due to constraints. Different AI models may respond differently to the same level of specificity.</p>"},{"location":"project-1/#control-variables","title":"Control Variables","text":"<ul> <li>Same product features and audience across all tests</li> <li>Same prompt wording for each version across all models</li> <li>Same evaluation criteria and scoring rubric</li> </ul>"},{"location":"project-1/#prompt-versions","title":"Prompt Versions","text":""},{"location":"project-1/#v1-minimal-instruction","title":"V1 (Minimal Instruction)","text":"<p>Write a product description for FitPulsePro Smartwatch</p>"},{"location":"project-1/#v2-basic-instruction","title":"V2 (Basic Instruction)","text":"<p>Write a product description for FitPulsePro smartwatch. Include key features like battery life and heart rate monitoring.</p>"},{"location":"project-1/#v3-detailed-instruction","title":"V3 (Detailed Instruction)","text":"<p>Write a product description for FitPulsePro smartwatch using ONLY the details provided below. Do not add any features not listed. Make it relatable and understandable for professionals aged 25-40.</p> <p>Required features to include: -   Heart rate monitoring with real-time tracking -   Built-in GPS for route mapping -   7-day battery life -   Water-resistant design</p> <p>Constraints: -   Target Audience: Health-conscious professionals aged 25-40 -   Tone: Professional yet approachable -   Word count: 100-150 words</p>"},{"location":"project-1/#output-versions","title":"Output Versions","text":""},{"location":"project-1/#v1-outputs-minimal-instruction","title":"V1 Outputs (Minimal Instruction)","text":"Model Output Claude ChatGPT Gemini Perplexity V1 Evaluation Clarity Accuracy Tone Creativity Structure Avg Compliance Claude 3 2 4 3 4 3.2 No extra features? N \u2022 Audience fit? Y ChatGPT 4 2 4 3 4 3.4 No extra features? N \u2022 Audience fit? Y Gemini 3 2 4 3 4 3.2 No extra features? N \u2022 Audience fit? Y Perplexity 4 2 5 4 5 4.0 No extra features? N \u2022 Audience fit? Y"},{"location":"project-1/#v2-outputs-basic-instruction","title":"V2 Outputs (Basic Instruction)","text":"Model Output Claude ChatGPT Gemini Perplexity V2 Evaluation Clarity Accuracy Tone Creativity Structure Avg Compliance Claude 3 2 4 3 4 3.2 No extra features? N \u2022 Audience fit? Y ChatGPT 5 3 4 3 5 4.0 No extra features? N \u2022 Audience fit? Y Gemini 3 2 3 2 3 2.6 No extra features? N \u2022 Audience fit? Y Perplexity 5 2 4 3 5 3.8 No extra features? N \u2022 Audience fit? Y"},{"location":"project-1/#v3-outputs-detailed-instruction","title":"V3 Outputs (Detailed Instruction)","text":"Model Output Claude ChatGPT Gemini Perplexity V3 Evaluation Clarity Accuracy Tone Creativity Structure Avg Compliance Claude 5 5 5 4 5 4.8 No extra features? Y \u2022 100\u2013150 words? Y \u2022 Audience fit? Y ChatGPT 5 5 5 4 5 4.8 No extra features? Y \u2022 100\u2013150 words? Y \u2022 Audience fit? Y Gemini 5 5 5 4 5 4.8 No extra features? Y \u2022 100\u2013150 words? Y \u2022 Audience fit? Y Perplexity 5 5 5 4 5 4.8 No extra features? Y \u2022 100\u2013150 words? Y \u2022 Audience fit? Y"},{"location":"project-1/#scoring-rubric-15","title":"Scoring Rubric (1\u20135)","text":"Metric Score 5 Score 3 Score 1 Clarity Crystal clear and unambiguous. Understandable with minor ambiguity. Confusing or incomplete. Accuracy Fully correct and on-goal. Partially correct with small errors. Incorrect or off-target. Tone Perfectly matched to context and audience. Acceptable but uneven. Inappropriate or mismatched. Creativity Original and compelling. Some novelty. Generic or stale. Structure Well organized with logical flow and helpful formatting. Some structure but minor issues. Disorganized or hard to scan."},{"location":"project-1/#results-insights","title":"Results &amp; Insights","text":""},{"location":"project-1/#performance-by-prompt-version","title":"\ud83d\udcca Performance by Prompt Version","text":"Prompt Type Clarity Accuracy Tone Creativity Structure Overall V1 (Minimal) 3.5 2.0 4.25 3.25 4.25 3.4/5 V2 (Basic) 4.0 2.25 3.75 2.75 4.25 3.4/5 V3 (Detailed) 5.0 5.0 5.0 4.0 5.0 4.8/5 <p>V1 \u2192 V3 Improvement: +41%</p>"},{"location":"project-1/#key-findings","title":"\ud83d\udd0d Key Findings","text":"<ol> <li>Accuracy Is Everything<ul> <li>V1 &amp; V2: ALL models hallucinated features (2.0-2.25/5).</li> <li>V3: PERFECT accuracy across all models (5.0/5).</li> <li>The phrase \"Do not add any features not listed\" eliminated 100% of hallucinations.</li> </ul> </li> <li>The V2 Problem<ul> <li>V2 actually performed worse than V1 in creativity (2.75 vs 3.25) and tone (3.75 vs 4.25). Partial specificity confused models more than complete freedom.</li> </ul> </li> <li>V3 Achieved Near-Perfect Results<ul> <li>Achieved 5.0/5 in Clarity, Accuracy, and Tone across the board.</li> <li>All models complied with word count and zero extra features were added.</li> </ul> </li> </ol>"},{"location":"project-1/#what-worked","title":"\u2705 What Worked","text":"<p>V3's Winning Formula: 1.  Explicit negative instruction: \"don't add extra details\" 2.  Specific feature list (4 items, bulleted) 3.  Clear audience: \"professionals aged 25-40\" 4.  Word count constraint: \"100-150 words\" 5.  Context + constraints used together.</p> <p>Result: Every model followed instructions perfectly, leading to a massive increase in quality.</p>"},{"location":"project-1/#what-didnt-work","title":"\u274c What Didn't Work","text":"<p>V1 Problems: -   Vague prompts = 100% feature hallucination. -   Every model added 5-10+ unauthorized features. -   Accuracy scored only 2.0/5.</p> <p>V2 Problems (The \"Half-Specific\" Trap): -   Adding some info without full constraints led to the worst scores in Creativity and Tone. -   Lesson: Go fully specific (V3) or stay fully open (V1). The middle ground often fails.</p>"},{"location":"project-1/#unexpected-findings","title":"\ud83d\udca1 Unexpected Findings","text":"<ol> <li>V3 wasn't less creative\u2014it scored 4.0 vs V2's 2.75. Clear boundaries enabled strategic creativity and storytelling vs. generic feature lists.</li> <li>Audience definition is magic\u2014Simply adding \"aged 25-40 professionals\" jumped Tone from 3.75 \u2192 5.0, a small change with a massive impact.</li> </ol>"},{"location":"project-1/#next-iteration-ideas","title":"\ud83d\ude80 Next Iteration Ideas","text":"<ol> <li>Test V4: Remove \"don't add extras\" from V3 to isolate its impact.</li> <li>Vary word counts: 50-75 words vs 150-200 words vs unlimited.</li> <li>Test instruction order: Constraints-first vs context-first.</li> <li>A/B test audience specificity: How detailed must the audience be?</li> <li>Try different constraint types: Format, style, and length variations.</li> </ol>"},{"location":"project-1/#key-takeaways","title":"\ud83c\udf93 Key Takeaways","text":"<ul> <li>Detailed prompts outperform vague prompts by 41%.</li> <li>Explicit boundaries eliminate hallucination (2.0 \u2192 5.0 accuracy).</li> <li>Partial specificity hurts more than it helps.</li> <li>Creativity thrives within clear boundaries, not despite them.</li> </ul>"},{"location":"project-1/#conclusion","title":"Conclusion:","text":"<p>Prompt specificity directly determines output quality. Detailed instructions with explicit constraints (V3) produced near-perfect results across all AI models tested.</p>"}]}