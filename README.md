# ğŸ”¬ Prompt Engineering Lab Journal

### A Systematic, 5-Part Study on Generative AI Instruction Effectiveness

---

## ğŸ¯ Project Objective

This journal serves as a personal laboratory to meticulously design, test, and evaluate various prompt structures (Chain-of-Thought, Role-based, etc.) to understand how specific variablesâ€”such as clarity, tone, and constraintsâ€”directly impact the quality, accuracy, and creativity of outputs from leading AI models.

## ğŸ”— Live Documentation Site

The full documentation, including all project findings, data visualizations, and scoring rubrics, is hosted live via GitHub Pages:

â¡ï¸ **[VIEW THE LIVE JOURNAL HERE](https://Amal-nellanhi.github.io/prompt-engineering-journal/)**


---

## ğŸ“‚ Repository Structure

| Folder/File | Purpose |
| :--- | :--- |
| `docs/` | Contains all project content written in **Markdown** (`project-1.md`, `index.md`). |
| `mkdocs.yml` | The primary configuration file, defining site title, theme, and navigation. |
| `site/` | **(IGNORED)** The directory generated by `mkdocs build`â€”the final HTML website. |
| `README.md` | This overview and project summary. |

---

## ğŸ› ï¸ Tech Stack & Methodology

- **Documentation:** Markdown
- **Static Site Generator:** [MkDocs](https://www.mkdocs.org/) (using the Material theme)
- **Deployment:** GitHub Pages
- **Models Tested:** Gemini (2.5 Flash), ChatGPT (GPT-4/GPT-4o), Claude (Sonnet 4.5), Perplexity AI

---

## ğŸ“œ License

This work is protected under the **All Rights Reserved** License. Please see the LICENSE file for details.
